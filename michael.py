# -*- coding: utf-8 -*-
"""michael.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mPw-T6ttcq2hbWp0DHNUyk23D1GHZZiE
"""

import pandas as pd
import numpy as np
from google.colab import drive

drive.mount('/content/gdrive')
root_path = "gdrive/My Drive/JPMC_Hackathon/"
data_path = root_path + "data/"

raw_data = pd.read_csv(data_path+"Goal4.csv")

df = pd.read_csv(data_path+"Goal4.csv")

df

df['Target'].unique()

len(df['SeriesDescription'].unique())

df['SeriesDescription'].unique()

len(df['Indicator'].unique())

df['Indicator'].unique()

len(df['SeriesCode'].unique())

df.describe()

df.columns

df = df.drop(['Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29',
       'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33',
       'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37',
       'Unnamed: 38', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41',
       'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45',
       'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49',
       'Unnamed: 50', 'Unnamed: 51'],axis=1)

df = df.drop(['Goal','Target','Indicator','TimePeriod'],axis=1)

df.describe()

len(df)

df.isna().sum()

df = df.drop(['TimeCoverage','UpperBound','LowerBound','GeoInfoUrl'],axis=1)

df = df.drop(['GeoAreaCode','BasePeriod','Age','FootNote','Source','Reporting Type','Units'],axis=1)

df = df.drop(['Nature'],axis=1)

df = df.drop(['Quantile'],axis=1)

df = df.drop(['Location'],axis=1)

df_afghanistan = df[(df.GeoAreaName == 'Afghanistan')]
df_afghanistan

df_afghanistan['Time_Detail'].unique()

len(df_afghanistan)

df_afghanistan

df_afghanistan['SeriesCode'].unique()

df['GeoAreaName'].unique()



df_afghanistan[df_afghanistan['SeriesCode'] == 'SE_TOT_PRFL']

df_afghanistan.columns

feat_mat = df.groupby(['Sex','Type of skill','Education level']).size().reset_index(name='Freq')
feat_mat

feat_mat.shape

feat_name_list = []

for s in feat_mat['Sex']:
  for t in feat_mat['Type of skill']:
    for e in feat_mat['Education level']:
      feat_name = s+"."+t+"."+e
      feat_name_list.append(feat_name)
feat_name_list = list(set(feat_name_list))

feat_name_list

len(feat_name_list)

listOfDataFrames = []
num_feat = 0
for feat in feat_name_list:
  num_feat += 1
  df_thisFeat = pd.DataFrame(columns=['GeoAreaName','Time_Detail',feat])
  featSplit = feat.split(".")
  print(featSplit)
  sex = featSplit[0]
  typeOfSkill = featSplit[1]
  educationLevel = featSplit[2]

  num_country = 0
  for country in df['GeoAreaName'].unique():
    num_country += 1
    df_country = df[(df.GeoAreaName == country)]

    yearsForThisCountry = df_country['Time_Detail'].unique()
    print(country,yearsForThisCountry)
    for year in yearsForThisCountry:
      print(feat,country,year)

      df_countryYear = df_country[df_country['Time_Detail']==year]
     
      df_subset = df_countryYear[(df_countryYear['Sex']==sex) & \
                             (df_countryYear['Type of skill']==typeOfSkill) & \
                             (df_countryYear['Education level']==educationLevel)]
      



      val = df_subset["Value"].values
      print(val)
      if len(val) == 1:
        print(df_subset)
        print(df_subset["Value"])
        d = {'GeoAreaName':country,'Time_Detail':year,feat:val[0]}
        print(d)
        print("******")
        df_thisFeat = df_thisFeat.append(d,ignore_index=True)
        print(df_thisFeat.shape)

    #if num_country == 10:
    #  break

  listOfDataFrames.append(df_thisFeat)
  #if num_feat == 3:
  #    break

listOfDataFrames[0]

listOfDataFrames[1]

listOfDataFrames[2]

listOfDataFrames[3]

listOfDataFrames[4]

listOfDataFrames[5]

len(listOfDataFrames)

listOfDataFrames_copy = listOfDataFrames

df_new = pd.merge(listOfDataFrames[0], listOfDataFrames[1],  how='left', left_on=['GeoAreaName','Time_Detail'], right_on = ['GeoAreaName','Time_Detail'])
for i in range(2,18):
  df_new = pd.merge(df_new, listOfDataFrames[i],  how='left', left_on=['GeoAreaName','Time_Detail'], right_on = ['GeoAreaName','Time_Detail'])



df_new

df_new.columns

df_origCols = df_new[['GeoAreaName','Time_Detail']]

df_dataOnly = df_new[['BOTHSEX.SKILL_READ.GRAD23',
       'BOTHSEX.SKILL_READ.LOWSEC', 'FEMALE.SKILL_MATH.GRAD23',
       'FEMALE.SKILL_MATH.LOWSEC', 'MALE.SKILL_MATH.GRAD23',
       'BOTHSEX.SKILL_MATH.PRIMAR', 'MALE.SKILL_READ.GRAD23',
       'MALE.SKILL_MATH.LOWSEC', 'FEMALE.SKILL_READ.LOWSEC',
       'BOTHSEX.SKILL_READ.PRIMAR', 'FEMALE.SKILL_READ.GRAD23',
       'BOTHSEX.SKILL_MATH.LOWSEC', 'MALE.SKILL_READ.PRIMAR',
       'FEMALE.SKILL_READ.PRIMAR', 'BOTHSEX.SKILL_MATH.GRAD23',
       'MALE.SKILL_MATH.PRIMAR', 'MALE.SKILL_READ.LOWSEC',
       'FEMALE.SKILL_MATH.PRIMAR']]

df_origCols

df_dataOnly

dataColNames = df_dataOnly.columns
X = df_dataOnly.to_numpy()

X

dataColNames

# knn imputation

import numpy as np
from sklearn.impute import KNNImputer
nan = np.nan
X = df_dataOnly.to_numpy()
imputer = KNNImputer(n_neighbors=3, weights="uniform")
df_imputeDataOnly = imputer.fit_transform(X)

df_imputeDataOnly = pd.DataFrame(data=df_imputeDataOnly,columns=dataColNames)

df_imputeDataOnly

df_imputed = pd.concat([df_origCols, df_imputeDataOnly], axis=1)

df_imputed

df_imputed

df_imputed.to_csv(data_path+"df_imputed.csv")

